# Tutor-IA

## Ãndice

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Arquitectura y TecnologÃ­as](#arquitectura-y-tecnologÃ­as-utilizadas)
3. [InstalaciÃ³n y EjecuciÃ³n](#-instalaciÃ³n-y-ejecuciÃ³n)
4. [Funcionamiento del sistema RAG](#funcionamiento-del-sistema-rag)
5. [Casos de uso recomendados](#casos-de-uso-recomendados)
6. [Checklist de contribuciÃ³n o desarrollo futuro](#checklist-de-contribuciÃ³n-o-desarrollo-futuro)
7. [API](#api-de-gestiÃ³n-de-apuntes-y-tutorÃ­a)


# IntroducciÃ³n

**Tutor-IA** es una plataforma educativa potenciada por inteligencia artificial diseÃ±ada para facilitar el estudio a travÃ©s del procesamiento y explicaciÃ³n personalizada de apuntes. Su objetivo principal es ayudar a estudiantes a comprender mejor sus materiales acadÃ©micos, respondiendo a preguntas, generando resÃºmenes y ofreciendo explicaciones adaptadas al nivel y contexto del alumno.

Esta herramienta combina modelos de lenguaje avanzados con tÃ©cnicas de recuperaciÃ³n de informaciÃ³n para garantizar respuestas precisas basadas en los apuntes propios del estudiante, fomentando un aprendizaje eficiente y personalizado.

# Arquitectura y TecnologÃ­as Utilizadas

Tutor-IA estÃ¡ construido sobre una arquitectura moderna que combina servicios backend robustos con una interfaz de usuario intuitiva. A continuaciÃ³n, se describen las principales tecnologÃ­as y componentes que conforman el proyecto:

- **FastAPI:** Framework para la creaciÃ³n de APIs RESTful rÃ¡pidas y eficientes en Python. Se utiliza para gestionar las peticiones del frontend y ejecutar la lÃ³gica de negocio, incluyendo la integraciÃ³n con modelos de lenguaje y procesamiento de documentos.

- **Streamlit:** Biblioteca para construir interfaces web interactivas y fÃ¡ciles de usar, orientada a aplicaciones de datos y machine learning. En Tutor-IA, Streamlit ofrece la UI donde los usuarios pueden interactuar con el tutor y gestionar sus apuntes.

- **Modelos de lenguaje (LLM):** Se emplean modelos como GPT-3.5 o Groq para generar respuestas y explicaciones basadas en el contexto proporcionado por los apuntes del usuario, utilizando tÃ©cnicas de RecuperaciÃ³n Aumentada por GeneraciÃ³n (RAG).

- **RAG (Retrieval-Augmented Generation):** TÃ©cnica que combina bÃºsqueda de informaciÃ³n en documentos relevantes con generaciÃ³n de texto para proporcionar respuestas mÃ¡s precisas y contextualizadas. Tutor-IA utiliza RAG para buscar fragmentos relevantes de los apuntes y enriquecer las respuestas del modelo.

- **FAISS (Facebook AI Similarity Search):** Motor de bÃºsqueda eficiente para grandes colecciones de vectores que permite realizar bÃºsquedas rÃ¡pidas de fragmentos de texto similares. En Tutor-IA, FAISS almacena y consulta las representaciones vectoriales de los chunks de apuntes para facilitar la recuperaciÃ³n de informaciÃ³n contextual.

- **Almacenamiento y Procesamiento de Apuntes:** Los documentos subidos por el usuario se procesan y segmentan en chunks para su posterior indexaciÃ³n y bÃºsqueda contextual mediante FAISS.

Esta combinaciÃ³n tecnolÃ³gica asegura un sistema escalable, eficiente y con una experiencia de usuario centrada en la personalizaciÃ³n y calidad educativa.


# API de GestiÃ³n de Apuntes y TutorÃ­a

Esta API ofrece un conjunto de endpoints diseÃ±ados para gestionar apuntes acadÃ©micos, responder preguntas basadas en contenido vectorizado (RAG), evaluar desarrollos, generar explicaciones adaptadas y enriquecer apuntes. EstÃ¡ construida sobre FastAPI y usa tecnologÃ­as como FAISS para bÃºsqueda vectorial y el modelo Groq para generaciÃ³n de lenguaje natural.

## âš™ï¸ InstalaciÃ³n y EjecuciÃ³n

### ğŸ“‹ Requisitos del Sistema

- Python 3.10 o superior
- Git instalado
- Recomendado: entorno virtual (venv, poetry o conda)
- ConexiÃ³n a internet para instalaciÃ³n de dependencias y uso de Groq API y OpenAi API

---

### ğŸ§ª Instrucciones Paso a Paso

#### 1. ğŸ”„ Clonar el repositorio

```bash
git clone https://github.com/tuusuario/tutor-ia.git
cd tutor-ia
```

#### 2. ğŸ§° Crear el entorno virtual
```bash
python3 -m venv .venv
source .venv/bin/activate   # En Linux/macOS
.venv\Scripts\activate      # En Windows
```

#### 3. ğŸ“¦ Instalar dependencias
```bash
pip install -r requirements.txt
```

#### 4. ğŸš€ Lanzar la API
```bash
uvicorn src.api.main:app --reload
```
La API estarÃ¡ disponible en http://localhost:8000
Puedes acceder a la documentaciÃ³n interactiva Swagger en http://localhost:8000/docs

Recuerda definir tu archivo .env con las claves necesarias, como GROQ_API_KEY, antes de lanzar la API.

#### 5. ğŸ–¥ï¸ Lanzar la interfaz en Streamlit

```bash
streamlit run interfaz/main.py
```

# Endpoints Principales

## 1. /responder_pregunta (GET) (Deprecado)

DescripciÃ³n:
Responde a una pregunta especÃ­fica basada en la materia y tema indicados, usando un enfoque Retrieval-Augmented Generation (RAG) para aprovechar el contexto de los apuntes.

ParÃ¡metros:
	â€¢	materia (string, requerido): Nombre de la materia.
	â€¢	tema (string, requerido): Nombre del tema dentro de la materia.
	â€¢	pregunta (string, requerido): La pregunta que desea responder el usuario.

Respuesta:

```json
{ "respuesta": "Texto con la respuesta generada basada en los apuntes." }
```

## 2. /explicar_ como_nino (GET)

DescripciÃ³n:
Genera una explicaciÃ³n de un tema especÃ­fico, adaptada para que un niÃ±o de 12 aÃ±os pueda entenderla.

ParÃ¡metros:
	â€¢	materia (string, requerido): Nombre de la materia.
	â€¢	tema (string, requerido): Nombre del tema dentro de la materia.

Respuesta:

```json
{
	"explicacion": "Texto explicativo simplificado para niÃ±os."
}
```

## 3. /procesar_apunte (POST)

DescripciÃ³n:
Procesa un nuevo archivo de apunte subido por el usuario, analiza su contenido, lo divide en chunks y actualiza el vectorstore correspondiente.

ParÃ¡metros:
	â€¢	materia (form data, requerido): Nombre de la materia.
	â€¢	tema (form data, requerido): Nombre del tema.
	â€¢	archivo (file, requerido): Archivo de apunte en formato compatible.

```json
{
  "mensaje": "Mensaje indicando el resultado del procesamiento."
}
```

## 4. /evaluar_desarrollo (POST)

DescripciÃ³n:
EvalÃºa un desarrollo escrito por el alumno comparÃ¡ndolo con los apuntes disponibles para la materia y tema indicados.

ParÃ¡metros (JSON body):
	â€¢	materia (string): Nombre de la materia.
	â€¢	tema (string): Nombre del tema.
	â€¢	titulo_tema (string): TÃ­tulo del desarrollo.
	â€¢	desarrollo (string): Texto del desarrollo a evaluar.

Respuesta:

```json
{
  "evaluacion": "Resultado cuantitativo o cualitativo de la evaluaciÃ³n."
}
```
## 5. /materias (GET)

DescripciÃ³n:
Devuelve un listado de todas las materias disponibles (directorio de vectorstores).

Respuesta

```json
[
  "historia",
  "matematicas",
  "biologia"
]
```

## 6. /temas (GET)

DescripciÃ³n:
Devuelve un listado de los temas disponibles para una materia concreta.

ParÃ¡metros:
	â€¢	materia (string, requerido): Nombre de la materia.

Respuesta:

```json
[
  "Segunda guerra mundial",
  "Edad media",
  "Renacimiento"
]
```

## 7. /debug/vectorstores (GET)

DescripciÃ³n:
Endpoint de depuraciÃ³n para listar todos los vectorstores existentes en el sistema.

Respuesta:

```json
[
  "historia__segunda_guerra_mundial",
  "matematicas__algebra",
  "biologia__celulas"
]
```

## 8. /enriquecer_apuntes (POST)

DescripciÃ³n:
Permite enriquecer apuntes existentes con informaciÃ³n adicional generada automÃ¡ticamente, actualizando la base de datos de chunks y temas.

ParÃ¡metros:
	â€¢	materia (string, requerido): Nombre de la materia.
	â€¢	tema (string, requerido): Nombre del tema.

```json	
{
  "mensaje": {
    "chunks_creados": 10,
    "subtemas_agregados": ["subtema1", "subtema2"],
    "detalle": []
  },
  "ya_analizado": false
}
```

## 9. /generar_ clase_magistral (POST)

DescripciÃ³n:
Genera una clase magistral completa para una materia y tema dados, combinando subtemas y almacenando el resultado en los apuntes.

ParÃ¡metros:
	â€¢	materia (string, requerido): Nombre de la materia.
	â€¢	tema (string, requerido): Nombre del tema.

Respuesta:

```json
{
  "mensaje": "Clase magistral generada correctamente."
}
```

## 10. /chat_ explica_simple (POST)

DescripciÃ³n:
API para el chatbot que responde preguntas basÃ¡ndose en el contexto de apuntes, con manejo avanzado de preguntas fuera de contexto y fallback para respuestas genÃ©ricas.

ParÃ¡metros (JSON body):
	â€¢	materia (string): Materia de referencia.
	â€¢	tema (string): Tema de referencia.
	â€¢	historial (lista de mensajes): Historial de la conversaciÃ³n.

Respuesta:

```json
{
  "respuesta": "Respuesta del tutor acadÃ©mico.",
  "historial": [
    {"role": "usuario", "content": "Â¿QuiÃ©n fue Hitler?"},
    {"role": "tutor", "content": "Respuesta detallada basada en apuntes e IA."}
  ]
}
```

# ğŸ—ï¸ Arquitectura del Proyecto

La arquitectura de `Tutor-IA` estÃ¡ organizada en una estructura modular y escalable, orientada a facilitar el desarrollo de funcionalidades educativas basadas en IA. A continuaciÃ³n se detalla la estructura principal del proyecto y la funciÃ³n de cada carpeta o archivo relevante:

### ğŸ“ Estructura principal del proyecto

```plaintext
tutor-ia/
â”œâ”€â”€ .devcontainer/              # ConfiguraciÃ³n para contenedores de desarrollo (opcional)
â”œâ”€â”€ .env                        # Variables de entorno locales
â”œâ”€â”€ .gitattributes              # Reglas de Git para atributos de archivos
â”œâ”€â”€ .gitignore                  # Archivos y carpetas ignoradas por Git
â”œâ”€â”€ audios/                     # Carpeta para audios generados (opcional)
â”œâ”€â”€ data/                       # Carpeta para datos adicionales (p. ej., docs.json)
â”œâ”€â”€ logs_chat.txt               # Registro de interacciones del chat
â”œâ”€â”€ README.md                   # DocumentaciÃ³n principal del proyecto
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ runtime.txt                 # Requisito de entorno para despliegues (ej. Render)
â”œâ”€â”€ streamlit_app.py            # Frontend visual del proyecto en Streamlit
â”œâ”€â”€ tutor_ia_logo.png           # Logo del proyecto
â”œâ”€â”€ uploads/                    # Apuntes PDF subidos por el usuario
â”œâ”€â”€ src/                        # CÃ³digo fuente principal
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes/             # Endpoints de FastAPI, incluyendo CLI y Chat
â”‚   â”‚       â””â”€â”€ cli_routes.py   # Punto principal de la API
â”‚   â”œâ”€â”€ apuntes/
â”‚   â”‚   â”œâ”€â”€ rag/                # MÃ³dulos de vectorizaciÃ³n y bÃºsqueda
â”‚   â”‚   â”‚   â””â”€â”€ vectorstores/   # FAISS Vectorstores generados por materia/tema
â”‚   â”‚   â””â”€â”€ scripts/
â”‚   â”‚       â””â”€â”€ agents/         # Agentes generativos (clase magistral, enriquecimiento, etc.)
â”‚   â”‚       â””â”€â”€ agent_tools.py  # Herramientas de postprocesado
â”‚   â”œâ”€â”€ services/               # LÃ³gica de negocio para responder, evaluar, enriquecer, etc.
â”‚   â””â”€â”€ config.py               # Variables de entorno y claves API
â””â”€â”€ main.py                     # Entry point para lanzar FastAPI
```

### ğŸ§© MÃ³dulos clave

- **`api/routes/cli_routes.py`**  
  Contiene todos los endpoints expuestos por FastAPI: subida de apuntes, generaciÃ³n de clases magistrales, chat educativo, enriquecimiento, etc.

- **`apuntes/rag/`**  
  AquÃ­ se almacenan los vectorstores de FAISS que permiten bÃºsquedas semÃ¡nticas rÃ¡pidas sobre los apuntes vectorizados.

- **`apuntes/scripts/agents/`**  
  Agentes que generan contenido automÃ¡ticamente: clases magistrales, subtemas avanzados, validaciÃ³n de calidad, etc.

- **`services/`**  
  Funciones core que procesan peticiones, ejecutan lÃ³gica y devuelven respuestas. Es la capa intermedia entre los endpoints y los modelos o herramientas externas.

- **`uploads/`**  
  Carpeta donde se almacenan temporalmente los archivos PDF subidos antes de ser procesados.

- **`config.py`**  
  Define variables como claves de API, rutas por defecto y configuraciones reutilizables.


## ğŸ”„ Flujo de Trabajo: Subida de Apuntes â†’ VectorizaciÃ³n â†’ Consulta â†’ Enriquecimiento

El flujo principal del proyecto **Tutor-IA** sigue una secuencia lÃ³gica que permite aprovechar al mÃ¡ximo los apuntes del estudiante mediante tÃ©cnicas de procesamiento, bÃºsqueda semÃ¡ntica y generaciÃ³n asistida por IA:

1. **ğŸ“¤ Subida del Apunte**  
   El usuario sube un archivo PDF a travÃ©s del endpoint `/procesar_apunte`, indicando la `materia` y el `tema` correspondiente.

2. **ğŸ§¹ Limpieza y Troceado**  
   El contenido del PDF se convierte en texto, se limpia (eliminando cabeceras, repeticiones, frases limitantes...) y se divide en fragmentos (chunks) coherentes desde el punto de vista semÃ¡ntico.

3. **ğŸ“¦ VectorizaciÃ³n e IndexaciÃ³n (FAISS)**  
   Los chunks son transformados en vectores mediante un modelo de embeddings. Estos vectores se almacenan en Ã­ndices FAISS separados por `materia` y `tema`, permitiendo bÃºsquedas eficientes por similitud semÃ¡ntica.

4. **ğŸ” Consulta del Usuario (RAG)**  
   Cuando el usuario realiza una pregunta, el sistema localiza los chunks mÃ¡s relevantes mediante bÃºsqueda vectorial y construye un prompt contextualizado que se envÃ­a a un modelo LLM (Groq) para generar una respuesta fundamentada en los apuntes del alumno.

5. **ğŸ§  Enriquecimiento SemiautomÃ¡tico**  
   A travÃ©s del endpoint `/enriquecer_apuntes`, el sistema analiza los apuntes existentes, detecta lagunas de contenido, y sugiere subtemas adicionales. Luego genera desarrollos completos para cada subtema y los incorpora al vectorstore, ampliando asÃ­ la base de conocimiento sin intervenciÃ³n manual.

Este flujo garantiza que el sistema evolucione con el tiempo, se mantenga centrado en los contenidos del estudiante, y mejore progresivamente su capacidad de respuesta mediante enriquecimiento continuo.

## ğŸ§  Funcionamiento del sistema RAG

### ğŸ” Â¿QuÃ© es RAG (Retrieval-Augmented Generation)?

**RAG** es una tÃ©cnica que combina dos enfoques en modelos de lenguaje:

- **Retrieval** (recuperaciÃ³n): busca informaciÃ³n relevante en una base de datos o documentos antes de responder.
- **Augmented Generation** (generaciÃ³n aumentada): el modelo genera la respuesta basÃ¡ndose tanto en el contexto recuperado como en su conocimiento general.

Esto permite generar respuestas **mÃ¡s precisas y personalizadas**, incluso en dominios especÃ­ficos como apuntes acadÃ©micos.

---

### ğŸ§¾ Â¿CÃ³mo se usan FAISS y los apuntes vectorizados?

1. ğŸ“¥ Cuando un estudiante sube un apunte en PDF, se analiza y se divide en fragmentos o *chunks* de texto.
2. ğŸ§  Cada fragmento se convierte en un vector numÃ©rico utilizando modelos de embeddings de Hugging Face.
3. ğŸ’¾ Estos vectores se almacenan en un Ã­ndice **FAISS**, organizado por materia y tema (`src/apuntes/rag/vectorstores`).
4. ğŸ” Cuando se hace una pregunta, se transforma en vector y se compara con los fragmentos existentes en FAISS.
5. ğŸ“š Los fragmentos mÃ¡s similares (contexto relevante) se pasan como input al modelo generativo para producir una respuesta fundamentada.

---

### ğŸ¤” Â¿CuÃ¡ndo se considera una pregunta relevante?

El sistema utiliza la funciÃ³n `es_pregunta_relevante()` del mÃ³dulo `rag_local.py`, que:

1. Convierte la pregunta en vector.
2. La compara con los vectores de los apuntes del tema correspondiente.
3. Si alguno supera un umbral de similitud determinado, se considera **relevante**.

---

### âš–ï¸ Â¿Y si no es relevante?

- Si la pregunta no es considerada relevante, se comprueba si es una **pregunta genÃ©rica** (ej. "hazme un resumen").
- En ese caso, se fuerza una bÃºsqueda contextual amplia usando todo el tema.
- Si no encaja en ninguna categorÃ­a, el sistema devuelve un mensaje indicando que no puede responder fuera de contexto.

---

> ğŸ§  Este enfoque permite un equilibrio entre precisiÃ³n y flexibilidad, dando prioridad a la informaciÃ³n contenida en los apuntes y evitando respuestas alucinadas.

## âœ… Casos de uso recomendados

Esta plataforma estÃ¡ diseÃ±ada para estudiantes y profesionales que deseen **aprovechar la inteligencia artificial para mejorar su aprendizaje**. A continuaciÃ³n, se describen los principales casos de uso:

---

### ğŸ“¤ Subir apuntes y enriquecerlos automÃ¡ticamente

- Los usuarios pueden subir apuntes en formato PDF clasificados por **materia** y **tema**.
- El sistema analiza el contenido, lo vectoriza y lo almacena de forma eficiente.
- Luego, se puede ejecutar un proceso de **enriquecimiento automÃ¡tico** que detecta lagunas de contenido y aÃ±ade subtemas desarrollados por la IA, mejorando asÃ­ la calidad del material de estudio.

---

### â“ Formular preguntas sobre temas concretos

- El usuario puede hacer preguntas directamente sobre los temas que ha subido.
- El sistema utiliza RAG (Retrieval-Augmented Generation) para buscar informaciÃ³n relevante en los apuntes y generar una respuesta coherente, confiable y adaptada.
- TambiÃ©n se pueden hacer preguntas genÃ©ricas como â€œhazme un resumenâ€ o â€œexplica este temaâ€.

---

### ğŸ§‘â€ğŸ« Simular conversaciones educativas con IA

- Mediante el chat integrado, es posible mantener una conversaciÃ³n fluida con un **tutor acadÃ©mico virtual**.
- Se puede pedir explicaciones con distintos niveles de complejidad, incluyendo el modo **â€œexplÃ­calo como si tuviera 12 aÃ±osâ€**.
- Ideal para repasar, resolver dudas o reforzar el aprendizaje de forma interactiva.

---

> ğŸ“š La plataforma no solo responde, sino que tambiÃ©n **evalÃºa desarrollos escritos**, genera clases magistrales completas y ofrece un sistema adaptable al progreso del estudiante.

## ğŸ› ï¸ Checklist de contribuciÃ³n o desarrollo futuro

Este proyecto estÃ¡ en constante evoluciÃ³n. A continuaciÃ³n se presentan ideas, tareas pendientes y mejoras sugeridas para colaboradores o para el propio roadmap del proyecto.

---

> âœ¨ Si quieres contribuir, abre un Pull Request con una descripciÃ³n clara de la mejora y asegÃºrate de mantener la coherencia con la arquitectura general del proyecto.



---

## ğŸ›¡ï¸ Archivo `.env` requerido

Crea un archivo `.env` en la raÃ­z del proyecto con al menos la siguiente clave:

```env
GROQ_API_KEY=tu_clave_groq_aqui
```


---

## ğŸ‘¥ Autores

Este proyecto ha sido desarrollado por Eugenio BarquÃ­n en el marco de la III Edicion del  Bootcamp Inteligencia Artificial Full Stack de KeepCoding 

## ğŸ“„ Licencia

Distribuido bajo la licencia MIT. Consulta el archivo LICENSE para mÃ¡s informaciÃ³n.
